import numpy as np
import math
from scipy.optimize import BFGS
from scipy.optimize import minimize
from scipy.special import expit
from scipy.optimize import fmin
from scipy.optimize import fmin_tnc
from numpy.random import randn
from tensorflow.examples.tutorials.mnist import input_data
import tensorflow as tf
mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)
# load data
tr_im = mnist.train.images # training set
validation_X = mnist.validation.images # validation set
t_im = mnist.test.images # testing set
# labels
tr_lb = mnist.train.labels # training set
validation_Y = mnist.validation.labels # validation set
t_lb = mnist.test.labels # testing set



# vectorrize
def train2(X,Y): 
    num = X.shape[0]
    size = X.shape[1]
    label_amount = 10
    theta=np.zeros((size+1,label_amount)) # (784+1)*10
    J_theta = np.zeros(label_amount) # 10*1
    learning_rate = 1e-5
    X=np.insert(X,0,values=1.0,axis=1) # for theta[0]=1
#         np.dot(x.T,sum((y.T-a.T)))
    
    for i in range(100):
        h = expit(np.dot(X,theta)).reshape((55000,10))
        theta = theta + learning_rate*np.dot(X.T,Y-h)
#     J_theta = sum(np.multiply(np.log(h),Y)+np.multiply((1-Y),np.log(1-h))) / (-num)
#     result = np.array([theta])
    return theta
    
def deriv_J2(parameters,x,y):
    parameters = parameters.reshape(785,10)
    num = y.shape[0]
    a = np.dot(x,parameters)
#     print(sum(y.T-a.T).shape)
    #drv = np.dot(x.T,sum((y.T-a.T)))/(-num)
    drv = np.dot(x.T, y-a)/(-num)
    #print('drv',drv.shape)
    drv = drv.flatten()
    return drv
    
    def J_fun2(parameters,x,y):
    parameters = parameters.reshape(785,10)
    num = y.shape[0]
    h = sigmoid(np.dot(x,parameters)).reshape((num,10)) #55000*10
    num = y.shape[0]
    J_theta = -np.mean(np.multiply(np.log(h),y)+np.multiply((1-y),np.log(1-h)))
#     print('J', J_theta.shape)
#     print(J_theta)
    return J_theta
    
    # optimize 
def opt2(theta,X,Y):
    # test sizes 
#     X.reshape(55000,784)
#     Y.reshape(55000,10)
#     theta.reshape(785,10)
    # input sizes
    num = X.shape[0]
    size = X.shape[1]
    label_amount = Y.shape[1]
    # 
    X=np.insert(X,0,values=1,axis=1) # for theta[0]=1
    
    x0 = theta
    opt = minimize(J_fun2, x0, args=(X,Y), method='CG', jac=deriv_J2, options={"maxiter":5})
    return opt
    

def predict(X,theta):# theta--(size+1)*label_amount
    label_amount = 10
    # errorCount=0
    X = np.insert(X, 0, values=1, axis=1) # num*(size+1)
    num = X.shape[0]
    h_theta=expit(np.dot(X,theta)) # num*(size+1) * (size+1)*label_amount = num*label_amount
    h_theta_max = h_theta.max(axis=1)  # num*1
    h_theta_max_postion=h_theta.argmax(axis=1) # result
    return h_theta_max_postion

def get_accuracy(pred_y,Y):
    return sum(pred_y==Y)/Y.shape[0]
# ==expit
def sigmoid(a):
    return 1 / (1 + np.exp(-a))


t2 = train2(tr_im,tr_lb)
x0 = t2 #np.zeros([785,10])
new_t2 = opt2(x0,tr_im,tr_lb)
new_t2.fun
theta = new_t2.x.reshape(785,10)
y = predict(t_im,theta)
tr_lb_ary = tr_lb.nonzero()[1]
t_lb_ary = t_lb.nonzero()[1]
get_accuracy(y,t_lb_ary)

